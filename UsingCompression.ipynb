{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Using compression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Load movielens datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Import CSV files via pandas\n",
    "dset = 'movielens-1m'\n",
    "fdata = os.path.join(dset, 'ratings.dat.gz')\n",
    "fitem = os.path.join(dset, 'movies.dat')\n",
    "\n",
    "# pass in column names for each CSV\n",
    "r_cols = ['user_id', 'movie_id', 'rating', 'unix_timestamp']\n",
    "ratings = pd.read_csv(fdata, sep=';', names=r_cols, compression='gzip')\n",
    "\n",
    "m_cols = ['movie_id', 'title', 'genres']\n",
    "movies = pd.read_csv(fitem, sep=';', names=m_cols,\n",
    "                     dtype={'title': object, 'genres': object})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "movie_id     int64:dense\n",
       "title       object:dense\n",
       "genres      object:dense\n",
       "dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies.ftypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user_id           int64:dense\n",
       "movie_id          int64:dense\n",
       "rating            int64:dense\n",
       "unix_timestamp    int64:dense\n",
       "dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings.ftypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Storing in HDF5/PyTables in compressed form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "data_dir = \"compression\"\n",
    "if os.path.exists(data_dir):\n",
    "    shutil.rmtree(data_dir)\n",
    "os.mkdir(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def to_hdf5(ratings, movies, filters):\n",
    "    \n",
    "    class Ratings(tables.IsDescription):\n",
    "        user_id = tables.Int32Col(pos=0)\n",
    "        movie_id = tables.Int32Col(pos=1)\n",
    "        rating = tables.Int8Col(pos=2)\n",
    "        unix_timestamp = tables.Int64Col(pos=3)\n",
    "    \n",
    "    class Movies(tables.IsDescription):\n",
    "        movie_id = tables.Int32Col(pos=0)\n",
    "        title = tables.StringCol(100, pos=1)\n",
    "        genres = tables.StringCol(50, pos=2)\n",
    "    \n",
    "    def get_filename(filters):\n",
    "        if filters.complevel != 0:\n",
    "            complib = filters.complib if \":\" not in filters.complib else filters.complib.replace(\":\", \"-\")\n",
    "            shuffle = \"shuffle\" if filters.shuffle else \"noshuffle\"\n",
    "            filename = \"%s/%s-%d-%s.h5\" % (data_dir, complib, filters.complevel, shuffle)\n",
    "        else:\n",
    "            filename = \"%s/no-compressed.h5\" % (data_dir,)\n",
    "        return filename\n",
    "\n",
    "    filename = get_filename(filters)\n",
    "    print(\"Creating file:\", filename)\n",
    "    with tables.open_file(filename, \"w\") as f:\n",
    "        table_ratings = f.create_table(f.root, \"ratings\", Ratings, filters=filters, expectedrows=len(ratings))\n",
    "        table_ratings.append([ratings[col].values for col in ratings.ftypes.keys()])\n",
    "        table_movies = f.create_table(f.root, \"movies\", Movies, filters=filters, expectedrows=len(movies))\n",
    "        table_movies.append([movies[col].values for col in movies.ftypes.keys()])\n",
    "    return filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating file: compression/no-compressed.h5\n",
      "CPU times: user 27.5 ms, sys: 32.3 ms, total: 59.8 ms\n",
      "Wall time: 80.8 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "filters = tables.Filters(complevel=0, complib=\"zlib\", shuffle=True)\n",
    "h5file = to_hdf5(ratings, movies, filters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opened \"compression/no-compressed.h5\" with sec2 driver.\r\n",
      "movies                   Dataset {3883/Inf}\r\n",
      "    Attribute: CLASS scalar\r\n",
      "        Type:      5-byte null-terminated UTF-8 string\r\n",
      "        Data:  \"TABLE\"\r\n",
      "    Attribute: FIELD_0_FILL scalar\r\n",
      "        Type:      native int\r\n",
      "        Data:  0\r\n",
      "    Attribute: FIELD_0_NAME scalar\r\n",
      "        Type:      8-byte null-terminated UTF-8 string\r\n",
      "        Data:  \"movie_id\"\r\n",
      "    Attribute: FIELD_1_FILL scalar\r\n",
      "        Type:      1-byte null-terminated ASCII string\r\n",
      "        Data:  \"\"\r\n",
      "    Attribute: FIELD_1_NAME scalar\r\n",
      "        Type:      5-byte null-terminated UTF-8 string\r\n",
      "        Data:  \"title\"\r\n",
      "    Attribute: FIELD_2_FILL scalar\r\n",
      "        Type:      1-byte null-terminated ASCII string\r\n",
      "        Data:  \"\"\r\n",
      "    Attribute: FIELD_2_NAME scalar\r\n",
      "        Type:      6-byte null-terminated UTF-8 string\r\n",
      "        Data:  \"genres\"\r\n",
      "    Attribute: NROWS scalar\r\n",
      "        Type:      native long\r\n",
      "        Data:  3883\r\n",
      "    Attribute: TITLE null\r\n",
      "        Type:      1-byte null-terminated UTF-8 string\r\n",
      "\r\n",
      "    Attribute: VERSION scalar\r\n",
      "        Type:      3-byte null-terminated UTF-8 string\r\n",
      "        Data:  \"2.7\"\r\n",
      "    Location:  1:14950684\r\n",
      "    Links:     1\r\n",
      "    Chunks:    {425} 65450 bytes\r\n",
      "    Storage:   597982 logical bytes, 654500 allocated bytes, 91.36% utilization\r\n",
      "    Type:      struct {\r\n",
      "                   \"movie_id\"         +0    native int\r\n",
      "                   \"title\"            +4    100-byte null-terminated ASCII string\r\n",
      "                   \"genres\"           +104  50-byte null-terminated ASCII string\r\n",
      "               } 154 bytes\r\n",
      "ratings                  Dataset {1000209/Inf}\r\n",
      "    Attribute: CLASS scalar\r\n",
      "        Type:      5-byte null-terminated UTF-8 string\r\n",
      "        Data:  \"TABLE\"\r\n",
      "    Attribute: FIELD_0_FILL scalar\r\n",
      "        Type:      native int\r\n",
      "        Data:  0\r\n",
      "    Attribute: FIELD_0_NAME scalar\r\n",
      "        Type:      7-byte null-terminated UTF-8 string\r\n",
      "        Data:  \"user_id\"\r\n",
      "    Attribute: FIELD_1_FILL scalar\r\n",
      "        Type:      native int\r\n",
      "        Data:  0\r\n",
      "    Attribute: FIELD_1_NAME scalar\r\n",
      "        Type:      8-byte null-terminated UTF-8 string\r\n",
      "        Data:  \"movie_id\"\r\n",
      "    Attribute: FIELD_2_FILL scalar\r\n",
      "        Type:      native signed char\r\n",
      "        Data:  0\r\n",
      "    Attribute: FIELD_2_NAME scalar\r\n",
      "        Type:      6-byte null-terminated UTF-8 string\r\n",
      "        Data:  \"rating\"\r\n",
      "    Attribute: FIELD_3_FILL scalar\r\n",
      "        Type:      native long\r\n",
      "        Data:  0\r\n",
      "    Attribute: FIELD_3_NAME scalar\r\n",
      "        Type:      14-byte null-terminated UTF-8 string\r\n",
      "        Data:  \"unix_timestamp\"\r\n",
      "    Attribute: NROWS scalar\r\n",
      "        Type:      native long\r\n",
      "        Data:  1000209\r\n",
      "    Attribute: TITLE null\r\n",
      "        Type:      1-byte null-terminated UTF-8 string\r\n",
      "\r\n",
      "    Attribute: VERSION scalar\r\n",
      "        Type:      3-byte null-terminated UTF-8 string\r\n",
      "        Data:  \"2.7\"\r\n",
      "    Location:  1:1024\r\n",
      "    Links:     1\r\n",
      "    Chunks:    {7710} 131070 bytes\r\n",
      "    Storage:   17003553 logical bytes, 17039100 allocated bytes, 99.79% utilization\r\n",
      "    Type:      struct {\r\n",
      "                   \"user_id\"          +0    native int\r\n",
      "                   \"movie_id\"         +4    native int\r\n",
      "                   \"rating\"           +8    native signed char\r\n",
      "                   \"unix_timestamp\"   +9    native long\r\n",
      "               } 17 bytes\r\n",
      "H5tools-DIAG: Error detected in HDF5:tools (1.8.17) thread 140736151184320:\r\n",
      "  #000: h5tools_dump.c line 1836 in h5tools_dump_mem(): H5Sis_simple failed\r\n",
      "    major: Failure in tools library\r\n",
      "    minor: error in function\r\n",
      "  #001: h5tools_dump.c line 1836 in h5tools_dump_mem(): H5Sis_simple failed\r\n",
      "    major: Failure in tools library\r\n",
      "    minor: error in function\r\n"
     ]
    }
   ],
   "source": [
    "!h5ls -v {h5file}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Exercise 1\n",
    "\n",
    "PyTables comes with out-of-box support for a series of codecs.  Do a quick comparison between \"zlib\", \"bzip2\", and \"blosc\" for compression levels of 1 (fastest), 5 and 9 (slowest).  Which one compresses best?  Which one compresses faster?\n",
    "\n",
    "Also, Blosc being a meta-compressor, it has support for different codecs internally that can be selected from PyTables in the \"blosc:`codec`\" form.  Do another comparison between internal Blosc codecs, namely, \"blosc:blosclz\" (the default), \"blosc:lz4\", \"blosc:lz4hc\", \"blosc:snappy\", \"blosc:zlib\" and \"blosc:zstd\".\n",
    "\n",
    "Finally, avoid any compression totally (`complevel=0`).  How fast it is compared with existing codecs?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating file: compression/zlib-5-shuffle.h5\n",
      "CPU times: user 378 ms, sys: 21.3 ms, total: 400 ms\n",
      "Wall time: 426 ms\n",
      "Creating file: compression/blosc-blosclz-5-shuffle.h5\n",
      "CPU times: user 68.7 ms, sys: 12.4 ms, total: 81.1 ms\n",
      "Wall time: 82.6 ms\n",
      "Creating file: compression/blosc-lz4-5-shuffle.h5\n",
      "CPU times: user 37 ms, sys: 11.9 ms, total: 48.9 ms\n",
      "Wall time: 49.4 ms\n",
      "Creating file: compression/blosc-lz4hc-5-shuffle.h5\n",
      "CPU times: user 350 ms, sys: 15.5 ms, total: 366 ms\n",
      "Wall time: 374 ms\n",
      "Creating file: compression/blosc-snappy-5-shuffle.h5\n",
      "CPU times: user 46.9 ms, sys: 13.3 ms, total: 60.3 ms\n",
      "Wall time: 60.5 ms\n",
      "Creating file: compression/blosc-zlib-5-shuffle.h5\n",
      "CPU times: user 321 ms, sys: 15 ms, total: 336 ms\n",
      "Wall time: 337 ms\n",
      "Creating file: compression/blosc-zstd-5-shuffle.h5\n",
      "CPU times: user 198 ms, sys: 14.6 ms, total: 213 ms\n",
      "Wall time: 214 ms\n"
     ]
    }
   ],
   "source": [
    "for complib in (\"zlib\", \"blosc:blosclz\", \"blosc:lz4\", \"blosc:lz4hc\", \"blosc:snappy\", \"blosc:zlib\", \"blosc:zstd\"):\n",
    "    filters = tables.Filters(complevel=5, complib=complib, shuffle=True)\n",
    "    %time to_hdf5(ratings, movies, filters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Reading compressed datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "files = list(os.walk(data_dir))[0][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['blosc-blosclz-5-shuffle.h5',\n",
       " 'blosc-lz4-5-shuffle.h5',\n",
       " 'blosc-lz4hc-5-shuffle.h5',\n",
       " 'blosc-snappy-5-shuffle.h5',\n",
       " 'blosc-zlib-5-shuffle.h5',\n",
       " 'blosc-zstd-5-shuffle.h5',\n",
       " 'no-compressed.h5',\n",
       " 'zlib-5-shuffle.h5']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading file: blosc-blosclz-5-shuffle.h5\n",
      "CPU times: user 42 ms, sys: 14.3 ms, total: 56.3 ms\n",
      "Wall time: 76.2 ms\n",
      "Reading file: blosc-lz4-5-shuffle.h5\n",
      "CPU times: user 30.1 ms, sys: 10.6 ms, total: 40.7 ms\n",
      "Wall time: 56.1 ms\n",
      "Reading file: blosc-lz4hc-5-shuffle.h5\n",
      "CPU times: user 23.9 ms, sys: 8.57 ms, total: 32.4 ms\n",
      "Wall time: 33.2 ms\n",
      "Reading file: blosc-snappy-5-shuffle.h5\n",
      "CPU times: user 27.3 ms, sys: 7.84 ms, total: 35.1 ms\n",
      "Wall time: 33.9 ms\n",
      "Reading file: blosc-zlib-5-shuffle.h5\n",
      "CPU times: user 86.2 ms, sys: 8.68 ms, total: 94.9 ms\n",
      "Wall time: 97.8 ms\n",
      "Reading file: blosc-zstd-5-shuffle.h5\n",
      "CPU times: user 39.5 ms, sys: 6.2 ms, total: 45.7 ms\n",
      "Wall time: 45.6 ms\n",
      "Reading file: no-compressed.h5\n",
      "CPU times: user 7.75 ms, sys: 10.6 ms, total: 18.4 ms\n",
      "Wall time: 18.6 ms\n",
      "Reading file: zlib-5-shuffle.h5\n",
      "CPU times: user 77.2 ms, sys: 8.47 ms, total: 85.7 ms\n",
      "Wall time: 90 ms\n"
     ]
    }
   ],
   "source": [
    "for f in files:\n",
    "    print(\"Reading file:\", f)\n",
    "    with tables.open_file(os.path.join(data_dir, f)) as h5f:\n",
    "        %time h5f.root.ratings[:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Exercise 2\n",
    "\n",
    "Which codec and compression level can read the fastest?  How it does compare with reading an uncompressed dataset?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Exercise 3\n",
    "\n",
    "Blosc can use multithreading for compressing/decompressing, although it is disabled by default.  You can enable a multithreaded Blosc in a series of ways, but perhaps the easiest is to set the \"BLOSC_NTHREADS\" environment variable to the desired number of threads (typically the available number of cores in your computer).\n",
    "\n",
    "Execute the cell below and re-do the reading benchmarks and look at how the reading speed vary.  Pay special attention to the difference between the CPU times and wall times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "os.environ[\"BLOSC_NTHREADS\"] = \"4\"  # set to any other number you prefer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
